{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Great Expectations"
      ],
      "metadata": {
        "id": "S0KvgYslI64f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Great Expectations Library\n"
      ],
      "metadata": {
        "id": "9R147FfXJG4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step installs the Great Expectations library, which is an open-source framework for data quality testing. It allows you to define, validate, and document expectations for your datasets. The library helps ensure that your data is clean, consistent, and meets predefined quality standards. By installing it via pip, we can use the various functionalities of Great Expectations in the notebook."
      ],
      "metadata": {
        "id": "C7l5IWpkL7il"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGqDcWNh3Y_-"
      },
      "outputs": [],
      "source": [
        "!pip install great_expectations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Import Necessary Libraries"
      ],
      "metadata": {
        "id": "fWSO9h40JZjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we import two essential libraries:\n",
        "\n",
        "    - pandas: A powerful data manipulation library that provides data structures (like DataFrames) to handle and analyze structured data efficiently.\n",
        "    - great_expectations: The core library of the Great Expectations framework, imported as gx. This will be used to define expectations and validate data quality."
      ],
      "metadata": {
        "id": "qxtulC8RMBxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import great_expectations as gx"
      ],
      "metadata": {
        "id": "77qWdq8yVVEl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Load UCI Adult Dataset"
      ],
      "metadata": {
        "id": "Fdt5KucDJu-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we load the UCI Adult Dataset directly from a URL. This dataset contains demographic information and income data, such as age, education, hours worked per week, and income level. It is often used for machine learning tasks like classification. The pd.read_csv() function loads the data into a pandas DataFrame and assigns column names for easier access."
      ],
      "metadata": {
        "id": "vADES337MJHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
        "                 names=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
        "                        \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
        "                        \"hours-per-week\", \"native-country\", \"income\"])"
      ],
      "metadata": {
        "id": "ogHUyzFKdS5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Preview the Dataset"
      ],
      "metadata": {
        "id": "2BCIXXwdJyS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we use the head() function to display the first five rows of the dataset. This is a common method for quickly inspecting the data structure and ensuring the dataset has been loaded correctly."
      ],
      "metadata": {
        "id": "TBJnYRhQMKl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "OXpbbmRsVj0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Set Up Great Expectations Context and Data Source"
      ],
      "metadata": {
        "id": "WwljyFlFJ1A8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we initialize the Great Expectations context, which manages data sources, expectations, and validation processes. We then add a pandas data source to the context, allowing us to work with our pandas DataFrame as a data asset for further validation steps."
      ],
      "metadata": {
        "id": "F_p-ybfgMMYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = gx.get_context()\n",
        "data_source = context.data_sources.add_pandas(\"pandas\")\n",
        "data_asset = data_source.add_dataframe_asset(name=\"pd dataframe asset\")"
      ],
      "metadata": {
        "id": "SxSmTGmZVk5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Define and Create a Data Batch"
      ],
      "metadata": {
        "id": "IHl4W07zJ5-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we define a batch of data from the pandas DataFrame (df). A batch in Great Expectations represents a subset of the data that can be validated against expectations. We create a batch definition for the whole DataFrame and then use this definition to retrieve the batch of data for validation."
      ],
      "metadata": {
        "id": "djmfsBIEMRxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_definition = data_asset.add_batch_definition_whole_dataframe(\"batch definition\")\n",
        "batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df})"
      ],
      "metadata": {
        "id": "dTdpe1tVhpgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Define an Expectation for Column Values"
      ],
      "metadata": {
        "id": "JhVlKGYXJ8Tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we define an expectation for the education-num column in the dataset. The expectation specifies that the values in the education-num column should fall within a specified range (between 0 and 20). Expectations help us define what the valid range of data values should be for each column."
      ],
      "metadata": {
        "id": "gaIvn5Y-Mazw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expectation = gx.expectations.ExpectColumnValuesToBeBetween(\n",
        "    column=\"education-num\", min_value=0, max_value=20\n",
        ")"
      ],
      "metadata": {
        "id": "PJw-qrNyhsIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Validate the Data Against the Expectation\n"
      ],
      "metadata": {
        "id": "18DfcBimJ-du"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this final step, we validate the dataset (batch) against the previously defined expectation. The validate() method checks if the data in the education-num column meets the defined condition (values between 0 and 20). The result is printed to provide feedback on whether the data passed or failed the validation."
      ],
      "metadata": {
        "id": "bVaGQm0sMhan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_result = batch.validate(expectation)\n",
        "print(validation_result)"
      ],
      "metadata": {
        "id": "G9Od69YChtf7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}